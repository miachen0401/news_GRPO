{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc69f05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# @title üõ†Ô∏è One-Click Installation & Setup (Run once per session)\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"‚è≥ Starting Environment Setup... (This takes ~2 minutes)\")\n",
    "\n",
    "def run_cmd(cmd, message):\n",
    "    print(f\"   - {message}\")\n",
    "    try:\n",
    "        subprocess.check_call(cmd, shell=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   ‚ùå Error executing: {cmd}\")\n",
    "        raise e\n",
    "\n",
    "# --- 1. Install Core Dependencies ---\n",
    "# We install these first to leverage pre-built wheels\n",
    "run_cmd(\"pip install -q --upgrade pip\", \"Upgrading pip\")\n",
    "run_cmd(\n",
    "    \"pip install -q vllm transformers accelerate datasets bitsandbytes peft\",\n",
    "    \"Installing Core ML Libraries (vLLM, Transformers, etc.)\"\n",
    ")\n",
    "\n",
    "# --- 2. Install Verl (The RL Library) ---\n",
    "run_cmd(\n",
    "    \"pip install -q git+https://github.com/volcengine/verl.git\",\n",
    "    \"Installing Verl from Source\"\n",
    ")\n",
    "\n",
    "# --- 3. Fix Numpy Conflict (Crucial for Colab) ---\n",
    "# Colab uses Numpy 2.x by default, but Verl requires 1.x\n",
    "run_cmd(\n",
    "    \"pip install -q 'numpy<2.0.0' --force-reinstall\",\n",
    "    \"Downgrading Numpy to 1.x (Compatibility Fix)\"\n",
    ")\n",
    "\n",
    "# --- 4. Auto-Patch for Fast Training (SDPA) ---\n",
    "# This forces the library to use standard PyTorch attention instead of \n",
    "# waiting 15 mins for Flash Attention to compile.\n",
    "print(\"   - Patching library for SDPA (Fast Attention)...\")\n",
    "target_file = \"/usr/local/lib/python3.12/dist-packages/verl/workers/fsdp_workers.py\"\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    with open(target_file, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # The code we want to modify\n",
    "    search_str = \"actor_module_class.from_pretrained(\"\n",
    "    replace_str = \"actor_module_class.from_pretrained(attn_implementation='sdpa', \"\n",
    "\n",
    "    # IDEMPOTENT PATCHING: Only apply if not already present\n",
    "    if replace_str in content:\n",
    "        print(\"     ‚úÖ Library is already patched.\")\n",
    "    elif search_str in content:\n",
    "        new_content = content.replace(search_str, replace_str)\n",
    "        with open(target_file, 'w') as f:\n",
    "            f.write(new_content)\n",
    "        print(\"     ‚úÖ Patch applied successfully!\")\n",
    "    else:\n",
    "        print(\"     ‚ö†Ô∏è Warning: Could not find patch target. Verl version might have changed.\")\n",
    "else:\n",
    "    print(\"     ‚ùå Error: Verl library not found. Installation likely failed.\")\n",
    "\n",
    "# --- 5. Set Environment Variables ---\n",
    "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "elapsed = int(time.time() - start_time)\n",
    "print(f\"üéâ Setup Complete in {elapsed} seconds! You can run training now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2649e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# @title 2. Prepare Data (GSM8K)\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create directory for data\n",
    "os.makedirs(\"data/gsm8k\", exist_ok=True)\n",
    "\n",
    "# 1. Load the dataset\n",
    "dataset = datasets.load_dataset(\"openai/gsm8k\", \"main\")\n",
    "\n",
    "# 2. Define the formatting function\n",
    "# GRPO needs a \"prompt\" and a \"ground_truth\"\n",
    "def process_fn(example, idx, split):\n",
    "    # Standard GSM8K prompt structure\n",
    "    instruction = (\n",
    "        example[\"question\"] +\n",
    "        \"\\nAnswer the above math problem. \"\n",
    "        \"Think step by step. Output the final answer after ####.\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"data_source\": \"gsm8k\",\n",
    "        \"prompt\": [{\"role\": \"user\", \"content\": instruction}],\n",
    "        \"ability\": \"math\",\n",
    "        \"reward_model\": {\n",
    "            \"style\": \"rule\", \n",
    "            \"ground_truth\": example[\"answer\"]\n",
    "        },\n",
    "        \"extra_info\": {\"split\": split, \"index\": idx}\n",
    "    }\n",
    "\n",
    "# 3. Apply formatting\n",
    "train_dataset = dataset[\"train\"].map(lambda x, i: process_fn(x, i, \"train\"), with_indices=True)\n",
    "test_dataset = dataset[\"test\"].map(lambda x, i: process_fn(x, i, \"test\"), with_indices=True)\n",
    "\n",
    "# 4. Save to Parquet (Verl format)\n",
    "train_dataset.to_parquet(\"data/gsm8k/train.parquet\")\n",
    "test_dataset.to_parquet(\"data/gsm8k/test.parquet\")\n",
    "\n",
    "print(f\"‚úÖ Data ready! Train: {len(train_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(\"First example prompt:\", train_dataset[0]['prompt'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82bb33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# @title 4. Run Training (Polished & Drive Integrated)\n",
    "import os\n",
    "import sys\n",
    "from google.colab import drive\n",
    "\n",
    "# --- ‚öôÔ∏è USER SETTINGS ---\n",
    "SAVE_TO_DRIVE = True  # Set to False if you don't want to mount Drive\n",
    "EXPERIMENT_NAME = \"qwen-grpo-gsm8k\"\n",
    "MODEL_PATH = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "# --- 1. Setup Storage Paths ---\n",
    "if SAVE_TO_DRIVE:\n",
    "    drive.mount('/content/drive')\n",
    "    # Save directly to MyDrive so checkpoints survive runtime disconnects\n",
    "    local_dir = f\"/content/drive/MyDrive/verl_checkpoints/{EXPERIMENT_NAME}\"\n",
    "    print(f\"üíæ Checkpoints will be saved to: {local_dir}\")\n",
    "else:\n",
    "    local_dir = f\"checkpoints/{EXPERIMENT_NAME}\"\n",
    "    print(f\"üíæ Checkpoints will be saved locally: {local_dir}\")\n",
    "\n",
    "# --- 2. Set Environment Optimization ---\n",
    "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "# --- 3. Construct the Training Command ---\n",
    "print(\"üöÄ Starting GRPO Training...\")\n",
    "print(\"Logs will stream below. (Initialize time: ~1 min)\")\n",
    "\n",
    "cmd_parts = [\n",
    "    sys.executable, \"-m\", \"verl.trainer.main_ppo\",\n",
    "    \n",
    "    # --- Algorithm & Data ---\n",
    "    \"algorithm.adv_estimator=grpo\",\n",
    "    \"data.train_files=data/gsm8k/train.parquet\",\n",
    "    \"data.val_files=data/gsm8k/test.parquet\",\n",
    "    \"data.train_batch_size=4\",\n",
    "    \"data.val_batch_size=4\",\n",
    "    \"data.max_prompt_length=512\",\n",
    "    \"data.max_response_length=512\",\n",
    "    \n",
    "    # --- Model Configuration ---\n",
    "    f\"actor_rollout_ref.model.path={MODEL_PATH}\",\n",
    "    \"actor_rollout_ref.model.use_remove_padding=True\",\n",
    "    \"actor_rollout_ref.model.enable_gradient_checkpointing=True\",\n",
    "    \n",
    "    # --- Training Hyperparameters ---\n",
    "    \"actor_rollout_ref.rollout.n=4\",            # Number of generated responses per prompt\n",
    "    \"actor_rollout_ref.rollout.temperature=0.8\",\n",
    "    \"actor_rollout_ref.actor.optim.lr=1e-6\",    # Learning rate\n",
    "    \n",
    "    # --- Batch Sizes (Critical for Stability) ---\n",
    "    \"actor_rollout_ref.actor.ppo_mini_batch_size=4\",        \n",
    "    \"actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4\", \n",
    "    \"actor_rollout_ref.rollout.log_prob_micro_batch_size=4\",\n",
    "\n",
    "    # --- Hardware & Colab Optimizations ---\n",
    "    \"data.dataloader_num_workers=1\",       # Low worker count to save CPU\n",
    "    \"+ray_kwargs.ray_init.num_cpus=8\",     # Spoof CPU count to prevent Ray blocking\n",
    "    \"trainer.n_gpus_per_node=1\",\n",
    "    \"trainer.nnodes=1\",\n",
    "    \n",
    "    # --- Logging & Saving ---\n",
    "    \"trainer.logger=['console']\",\n",
    "    f\"trainer.project_name='{EXPERIMENT_NAME}'\",\n",
    "    f\"trainer.experiment_name='{EXPERIMENT_NAME}'\",\n",
    "    f\"trainer.default_local_dir='{local_dir}'\", # Where to save the model\n",
    "    \"++trainer.val_before_train=False\"\n",
    "]\n",
    "\n",
    "# --- 4. Execute ---\n",
    "cmd = \" \".join(cmd_parts)\n",
    "!{cmd}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
